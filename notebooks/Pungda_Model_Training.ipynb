{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 1: INSTALL LIBRARIES"
      ],
      "metadata": {
        "id": "EHxoVpSCLk3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW5wffu2LMd5",
        "outputId": "86288fea-8eb7-427b-b46f-3ba7447793d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Libraries installed.\n"
          ]
        }
      ],
      "source": [
        "# We need to install XGBoost and the library for TabNet.\n",
        "# The 'q' flag makes the output less verbose.\n",
        "\n",
        "!pip install -q xgboost\n",
        "!pip install -q pytorch-tabnet\n",
        "\n",
        "print(\"✅ Libraries installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 2: IMPORTS, DRIVE MOUNT, AND CONFIGURATION"
      ],
      "metadata": {
        "id": "rbRfKuCKL75J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import xgboost as xgb\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "import torch\n",
        "\n",
        "# --- Mount Drive ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configuration ---\n",
        "PROJECT_DIR = \"/content/drive/My Drive/Pungda\"\n",
        "DATASET_PATH = os.path.join(PROJECT_DIR, \"training_dataset_final.csv\")\n",
        "SCALERS_PATH = os.path.join(PROJECT_DIR, \"scalers.joblib\")\n",
        "MODEL_SAVE_DIR = os.path.join(PROJECT_DIR, \"models\")\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# --- Set Device ---\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Model save directory: {MODEL_SAVE_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_w-3HOHLXhO",
        "outputId": "97d2183e-d7dc-4d3c-b923-01d042235577"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cpu\n",
            "Model save directory: /content/drive/My Drive/Pungda/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 3: DATA LOADING AND PREPARATION"
      ],
      "metadata": {
        "id": "e2W6biLoMSSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We load the final dataset and the scalers we saved earlier.\n",
        "# This ensures we process our data exactly the same way every time.\n",
        "\n",
        "print(\"Loading data and scalers...\")\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "scalers = joblib.load(SCALERS_PATH)\n",
        "req_scaler = scalers['req']\n",
        "emb_scaler = scalers['emb']\n",
        "yield_scaler = scalers['yield']\n",
        "print(\"Data and scalers loaded successfully.\")\n",
        "\n",
        "# --- Define Features and Target ---\n",
        "# IMPORTANT: These must match the columns in the training dataset!\n",
        "requirement_cols = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
        "embedding_cols = [f'A{i:02d}' for i in range(64)]\n",
        "feature_cols = requirement_cols + embedding_cols\n",
        "target_col = 'yield'\n",
        "\n",
        "# --- Apply the Saved Scalers ---\n",
        "# We use .transform() here, NOT .fit_transform(), to prevent data leakage.\n",
        "df[requirement_cols] = req_scaler.transform(df[requirement_cols])\n",
        "df[embedding_cols] = emb_scaler.transform(df[embedding_cols])\n",
        "# We don't scale the target 'yield' yet, as models handle it differently.\n",
        "\n",
        "# --- Split Data for Training and Validation ---\n",
        "X = df[feature_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nData shapes:\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val:   {X_val.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val:   {y_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOo6AYDMLbFm",
        "outputId": "957ba22b-7bcb-48af-eac1-6992ecf09047"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data and scalers...\n",
            "Data and scalers loaded successfully.\n",
            "\n",
            "Data shapes:\n",
            "X_train: (43938, 71)\n",
            "X_val:   (10985, 71)\n",
            "y_train: (43938,)\n",
            "y_val:   (10985,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 4: MODEL 1 - XGBOOST (THE REIGNING CHAMPION)"
      ],
      "metadata": {
        "id": "PhuA8N1NP8pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Training XGBoost Model ---\")\n",
        "\n",
        "# Instantiate the XGBoost regressor.\n",
        "# Key parameters:\n",
        "#   - n_estimators: Number of boosting rounds (trees).\n",
        "#   - learning_rate: How much to shrink the contribution of each tree.\n",
        "#   - tree_method='hist': A much faster training method.\n",
        "#   - device='cuda': This tells XGBoost to use the GPU.\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    tree_method='hist',\n",
        "    device=device,\n",
        "    early_stopping_rounds=50 # Stop training if validation score doesn't improve\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=100 # Print progress every 100 rounds\n",
        ")\n",
        "\n",
        "# --- Evaluate the Model ---\n",
        "print(\"\\n--- Evaluating XGBoost ---\")\n",
        "preds = xgb_model.predict(X_val)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "mae = mean_absolute_error(y_val, preds)\n",
        "r2 = r2_score(y_val, preds)\n",
        "\n",
        "print(f\"Validation R² Score: {r2:.4f}\")\n",
        "print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "print(f\"Validation MAE: {mae:.4f}\")\n",
        "print(\"\\nMAE means the model's predictions are, on average, off by this many tons/hectare.\")\n",
        "print(\"R² of 1.0 is a perfect prediction.\")\n",
        "\n",
        "# --- Save the Trained Model ---\n",
        "XGB_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, \"xgboost_yield_model.json\")\n",
        "xgb_model.save_model(XGB_MODEL_PATH)\n",
        "print(f\"\\nXGBoost model saved to: {XGB_MODEL_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE-2IS7cLd55",
        "outputId": "3a6b1856-8668-4faf-9919-1748d2b83b7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training XGBoost Model ---\n",
            "[0]\tvalidation_0-rmse:34.23145\n",
            "[100]\tvalidation_0-rmse:7.80612\n",
            "[200]\tvalidation_0-rmse:7.74773\n",
            "[300]\tvalidation_0-rmse:7.72282\n",
            "[400]\tvalidation_0-rmse:7.70418\n",
            "[500]\tvalidation_0-rmse:7.68774\n",
            "[600]\tvalidation_0-rmse:7.67909\n",
            "[700]\tvalidation_0-rmse:7.67393\n",
            "[800]\tvalidation_0-rmse:7.66484\n",
            "[900]\tvalidation_0-rmse:7.65798\n",
            "[999]\tvalidation_0-rmse:7.65609\n",
            "\n",
            "--- Evaluating XGBoost ---\n",
            "Validation R² Score: 0.9546\n",
            "Validation RMSE: 7.6550\n",
            "Validation MAE: 3.2032\n",
            "\n",
            "MAE means the model's predictions are, on average, off by this many tons/hectare.\n",
            "R² of 1.0 is a perfect prediction.\n",
            "\n",
            "XGBoost model saved to: /content/drive/My Drive/Pungda/models/xgboost_yield_model.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------\n",
        "# CELL 5: MODEL 2 - TABNET (THE DEEP LEARNING CHALLENGER)\n",
        "# -----------------------------------------------------------------\n",
        "# TabNet requires data as NumPy arrays.\n",
        "\n",
        "print(\"\\n\\n--- Training TabNet Model ---\")\n",
        "\n",
        "# Convert data to NumPy arrays\n",
        "X_train_np = X_train.values\n",
        "y_train_np = y_train.values.reshape(-1, 1) # Reshape for TabNet\n",
        "X_val_np = X_val.values\n",
        "y_val_np = y_val.values.reshape(-1, 1)\n",
        "\n",
        "# Instantiate the TabNet Regressor\n",
        "tabnet_model = TabNetRegressor(\n",
        "    verbose=10,\n",
        "    seed=42,\n",
        "    device_name=device\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "tabnet_model.fit(\n",
        "    X_train=X_train_np, y_train=y_train_np,\n",
        "    eval_set=[(X_val_np, y_val_np)],\n",
        "    eval_name=['val'],\n",
        "    eval_metric=['mae'],\n",
        "    max_epochs=100,\n",
        "    patience=15, # Early stopping patience\n",
        "    batch_size=1024\n",
        ")\n",
        "\n",
        "# --- Evaluate the Model ---\n",
        "print(\"\\n--- Evaluating TabNet ---\")\n",
        "preds = tabnet_model.predict(X_val_np).flatten() # Flatten the output\n",
        "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "mae = mean_absolute_error(y_val, preds)\n",
        "r2 = r2_score(y_val, preds)\n",
        "\n",
        "print(f\"Validation R² Score: {r2:.4f}\")\n",
        "print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "print(f\"Validation MAE: {mae:.4f}\")\n",
        "\n",
        "# --- Save the Trained Model ---\n",
        "TABNET_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, \"tabnet_yield_model\")\n",
        "tabnet_model.save_model(TABNET_MODEL_PATH)\n",
        "print(f\"\\nTabNet model saved to: {TABNET_MODEL_PATH}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4LHH4AELhmv",
        "outputId": "45839016-d79b-4344-e6fd-65ead5124eaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Training TabNet Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1227.56252| val_mae: 14.48003|  0:00:03s\n",
            "epoch 10 | loss: 76.84739| val_mae: 3.93636 |  0:00:41s\n",
            "epoch 20 | loss: 66.27465| val_mae: 3.82626 |  0:01:17s\n",
            "epoch 30 | loss: 59.42333| val_mae: 3.62971 |  0:01:55s\n",
            "epoch 40 | loss: 54.07036| val_mae: 3.8592  |  0:02:32s\n",
            "epoch 50 | loss: 56.90972| val_mae: 3.72595 |  0:03:08s\n",
            "\n",
            "Early stopping occurred at epoch 58 with best_epoch = 43 and best_val_mae = 3.4972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating TabNet ---\n",
            "Validation R² Score: 0.9492\n",
            "Validation RMSE: 8.0979\n",
            "Validation MAE: 3.4972\n",
            "Successfully saved model at /content/drive/My Drive/Pungda/models/tabnet_yield_model.zip\n",
            "\n",
            "TabNet model saved to: /content/drive/My Drive/Pungda/models/tabnet_yield_model.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGfpWjytQVLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}